# Self-Refine CLI with Poetiq Parallel System

A self-refining AI agent powered by **llama.cpp** with true parallel inference on GPU.

## ğŸš€ Quick Start

```bash
# 1. Start the llama.cpp server (GPU)
start_server.bat

# 2. Run agent
python run_test.py "your task" --poetiq
```

## ğŸ—ï¸ Architecture

```
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚   PoetiqRunner   â”‚  â† Orchestrator
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â–¼               â–¼               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Worker 0 â”‚   â”‚Worker 1 â”‚   â”‚Worker 2 â”‚  â† 1 LLM call each (PARALLEL)
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚ VotingSystem â”‚  â† Pick best response
           â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                  â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚ ToolExecutor â”‚  â† Execute winner's tool
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Project Structure

```
self-refine-cli/
â”œâ”€â”€ core/                    # Core modules
â”‚   â”œâ”€â”€ llm_client.py       # llama.cpp client
â”‚   â”œâ”€â”€ poetiq.py           # Parallel workers system
â”‚   â”œâ”€â”€ agent.py            # Full self-refine agent
â”‚   â”œâ”€â”€ parsers.py          # Tool call extraction
â”‚   â”œâ”€â”€ prompts.py          # System prompts
â”‚   â”œâ”€â”€ evaluator.py        # Response evaluation
â”‚   â””â”€â”€ verification.py     # Code verification
â”œâ”€â”€ tools/                   # Agent tools
â”‚   â”œâ”€â”€ file_tools.py       # read_file, write_file, list_dir
â”‚   â””â”€â”€ command_tools.py    # python_exec, run_command
â”œâ”€â”€ config/
â”‚   â””â”€â”€ settings.py         # Configuration
â”œâ”€â”€ server/                  # llama.cpp binaries
â”œâ”€â”€ sandbox/                 # Agent workspace
â”œâ”€â”€ run_test.py             # Test runner
â”œâ”€â”€ start_server.bat        # Start GPU server
â””â”€â”€ stop_server.bat         # Stop server
```

## âš¡ Server Configuration

The llama.cpp server runs with:
- **6 parallel slots** for concurrent inference
- **Vulkan GPU** acceleration
- **16K context** window

## ğŸ§ª Usage

```bash
# Single agent
python run_test.py "list files in sandbox/"

# Parallel agents (3 workers, vote on best)
python run_test.py "create hello.py" --poetiq

# Parallel with 6 workers
python run_test.py "task" --poetiq -p 6

# Stress test
python run_test.py --stress 6
```

## ğŸ“Š Performance

| Mode | Time | 
|------|------|
| LM Studio (old) | ~5 min |
| **Poetiq + llama.cpp** | **~10s** |

## ğŸ› ï¸ Requirements

```
openai
requests
```

## ğŸ“œ Architecture & Sources

This project implements the **Poetiq Architecture** for autonomous AI reasoning:

### Core Papers & Research
- [Self-Refine Paper](https://arxiv.org/abs/2303.17651) - Iterative Refinement with Self-Feedback (Madaan et al., 2023)
- [Ryan Greenblatt's ARC-AGI Approach](https://github.com/rgreenblatt/arc_prism) - Getting 50% on ARC-AGI with GPT-4o (Program Synthesis)

### Poetiq Architecture (2025)
- [Poetiq GitHub Repo](https://github.com/poetiq-ai/poetiq-arc-agi-solver) - Official code
- [Poetiq Blog: Traversing the Frontier](https://poetiq.ai/posts/arcagi_announcement/) - Full technical breakdown
- [Poetiq Blog: Shatters ARC-AGI-2](https://poetiq.ai/posts/arcagi_verified/) - Verified results

### Key Concepts
| Concept | Description |
|---------|-------------|
| **Program Synthesis** | LLM generates Python code, not just text answers |
| **Test-Time Compute** | More inference time â†’ better results (log-linear) |
| **Verification Loop** | Execute code against examples, if fail â†’ feedback â†’ retry |
| **Self-Auditing** | System decides when solution is satisfactory |
| **Pareto-Optimal Routing** | Use cheap models for easy tasks, expensive for hard |

### ARC-AGI Benchmark
- [ARC Prize Official](https://arcprize.org/) - The benchmark that Poetiq conquered
- [ARC-AGI-2 Leaderboard](https://arcprize.org/leaderboard)

### llama.cpp
- [llama.cpp](https://github.com/ggerganov/llama.cpp) - Our local inference server

